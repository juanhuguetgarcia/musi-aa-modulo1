{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shap Values\n",
    "\n",
    "La interpretabilidad de los modelos es un \"tema caliente\", en muchas ocasiones no podremos entregar un modelo que sea una caja negra, donde no podamos explicar que está pasando realmente. \n",
    "\n",
    "En ciertas aréas es particularmente dificil adoptar modelos que sean cajas negras (medicina, banca, ... ), por lo tanto, cuanto mejor sea la interpretabilidad del modelo, mejor adopción tendremos.\n",
    "\n",
    "Para conseguir esta interpretabilidad de los modelos, podemos utilizar distintas herramientas: \n",
    "\n",
    "  - **Shap Values**\n",
    "  - Lime\n",
    "  - InterpretML\n",
    "  - ELI5\n",
    "  \n",
    "A lo largo de este tema nos vamos a centrar en la primera, los SHAP Values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/shap.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHAP significa **SHapley Additive exPlanations**, de este modo, para entender que son los SHAP values tenemos que saver que es un Shapley value. \n",
    "\n",
    "Un SHapley value es la media de las contribuciones marginales de cada elemento en las diferentes permutaciones de estos [Definicion matemática](https://math.stackexchange.com/questions/111580/shapley-value-formula#:~:text=I%20understand%20Shapley%20value%20in,%E2%88%92v(s)).\n",
    "\n",
    "Una vez conocemos que es un SHapley value, vamos a ver que es SHAP:\n",
    "\n",
    "[Lundberg & Lee (2016)](https://papers.nips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf) propusieron el SHAP value como una aproximación unida para explicar los resultados de cualquier modelo de machine learning, otorgandonos los siguientes beneficios: \n",
    "\n",
    "1. Interpretabilidad global. Los valores agregados de SHAP values nos indica cuanto contribuye cada predictor.\n",
    "1. Interpretabilidad local. Cada observacion tiene su conjunto de SHAP values, lo que nos da transparencia.\n",
    "1. Posibilidad de calcular SHAP para cualquier modelo basado en arboles.\n",
    "\n",
    "Dicho esto, vamos a ver como visualizar la explicabilidad de los modelos con SHAP en python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - importamos las librerías de base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## common libraries for Data Wrangling and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## sklearn: train test split, RandomForestRegressor, y mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "## import shap\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga los datos en un df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/winequality-red.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separar los datos en train + test (80% - 20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(df.drop(columns=[\"quality\"]),\n",
    "                                                    df['quality'],\n",
    "                                                    test_size = ##,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrerna un RandomForestRegressor como modelo para predecir la calidad del vino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=100,\n",
    "                              max_depth=4,\n",
    "                              random_state=0)\n",
    "\n",
    "## fit model with train data\n",
    "model.##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalua in-sample y out-of-sample para comprobar que no estamos cometiendo overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model.predict(##)\n",
    "y_pred_test = model.predict(##)\n",
    "\n",
    "mae_in_sample = np.sqrt(mean_squared_error(y_true=Y_train, y_pred=y_pred_train))\n",
    "mae_out_of_sample = np.sqrt(mean_squared_error(y_true=Y_test, y_pred=y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'In sample error: {mae_in_sample}')\n",
    "print(f'Out sample error: {mae_out_of_sample}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualiza la importancia de las características que devuelve el `Random Forest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.##\n",
    "features = X_train.##\n",
    "\n",
    "feat_importance = pd.DataFrame({'feature': features, 'importance': importances})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importance.set_index('feature')['importance'].sort_values().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspección de modelo usando SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a ver lo que podemos obtener con SHAP, y si en primera instancia los valores son similares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(model=##)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer(##)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(##)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos algún cambio menor, pero en lineas generales los valores son similares, pero de momento, no estamos ganando nada con respecto a la importancia de las variables que nos otorga RandomForest.\n",
    "\n",
    "Una cosa que podemos hacer con SHAP es obtener el signo del impacto, es decir, saber si las variables tienen un impacto positivo o negativo en el resultado final, vamos a verlo: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values=##)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este grafico podemos ver la siguiente información: \n",
    "\n",
    "- El eje vertical muestra la importancia de la variable \n",
    "- El eje horizontal muestra el efecto de cada punto para la predicción\n",
    "- El color muestra si el valor de la variable fue alto o bajo\n",
    "\n",
    "De este modo podemos empezar a entender nuestro modelo, sabiendo por ejemplo que un buen vino tiene: \n",
    "\n",
    "  - Alto contenido en alcohol\n",
    "  - Alto contenido en sulfatos\n",
    "  - Baja volatilidad con la acided\n",
    "  - Bajo ph\n",
    "  - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero todavía podemos ir mas allá y entender los impactos directos de cada una de las features a una predicción.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.force(shap_values[##])  ## el indice es el numero de linea del ejemplo del dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uib",
   "language": "python",
   "name": "uib"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
