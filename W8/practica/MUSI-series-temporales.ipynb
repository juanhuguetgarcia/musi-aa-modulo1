{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro a Series Temporales\n",
    "\n",
    "Las series temporales son secuencias de números ordenadas por un indice de tiempo, es decir, una lista de valores ordenados. Pueden ser `univariadas`, solo un valor por timestamp:\n",
    "\n",
    "|timestamp|value|\n",
    "|:---------:|:-----:|\n",
    "|09:00|1|\n",
    "|10:00|2|\n",
    "|11:00|4|\n",
    "|12:00|2|\n",
    "|13:00|1|\n",
    "|14:00|2|\n",
    "|15:00|4|\n",
    "|16:00|2|\n",
    "\n",
    "o `multivariadas`, donde recolectamos más de un dato/observación por timestamp.\n",
    "\n",
    "|timestamp|pressure_mmhg|temperature_deg_C|wind_knots|\n",
    "|:---------:|:-----:|:----:|:----:|\n",
    "|09:00|720|28|15|\n",
    "|10:00|730|29|16|\n",
    "|11:00|725|29|14|\n",
    "\n",
    "\n",
    "La predicción de series temporales presenta sus propios retos. El objetivo del analisis de las series temporales es ser capaz de aprovechar la naturaleza temporal del dato para poder realizar predicciones. Es decir, intentaremos aprovechar características como la tendencia y la estacionalidad para realizar modelos predictivos.\n",
    "\n",
    "![decomposition](img/ts-decomposition.png)\n",
    "\n",
    "La forma tradicional de tratar un problema de predicción de serie temporal es utilizando modelos autoregresivos (See [ARIMA](https://people.duke.edu/~rnau/411arim.htm) models). Es decir, basar una predicción en un momento `t` como una regresión basada en los valores de `t-1`a `t-n`. A los valores pasado los llamaremos `lags`. Por ejemplo,\n",
    "\n",
    "$y_t = \\theta \\times y_{t-1} + C$\n",
    "\n",
    "La expresión de arriba se puede ampliar con más lags, pero por lo general, el proceso de predicción de una serie temporal se basa en:\n",
    "\n",
    "1. Graficar la serie temporal, y descomponer en tendencia, estacionalidad y ruido.\n",
    "2. Modelizar la tendencia: $y_t = \\theta \\times t + C$\n",
    "3. Modelizar la componente estacional $ y_t = \\alpha \\sin(\\omega t) $\n",
    "3. Modelizar los residuos: $\\varepsilon \\sim N(0, \\sigma^2)$\n",
    "4. Sumar todas las componentes modelizadas\n",
    "\n",
    "## ML aplicado a Series temporales\n",
    "\n",
    "Recordemos que de forma genereal, un problema de ML supervisado se entiende como una funcion que mapea unas variables de entrada X, a una salida y:\n",
    "\n",
    "$\\hat{y} = h(X)$\n",
    "\n",
    "¿Cómo podríamos aunar los dos mundos? Basandonos en la idea general del modelo de AutoRegresion, podemos generarnos las features X de forma que podamos afrontar un problema de predicción de serie temporal como un problema de regresión supervisado.\n",
    "\n",
    "Dada una secuencia de números, podemos usar los datos de momentos anteriores como variables de entrada como valor de predicción. Si miramos el ejemplo anterior, podemos convertirlo en:\n",
    "\n",
    "\n",
    "|timestamp|value_t-2|value_t-1|value|\n",
    "|:---------:|:-----:|:----:|:----:|\n",
    "|09:00|NaN|NaN|1|\n",
    "|10:00|NaN|1|2|\n",
    "|11:00|1|2|4|\n",
    "|12:00|2|4|2|\n",
    "|13:00|4|2|1|\n",
    "|14:00|2|1|2|\n",
    "|15:00|1|2|4|\n",
    "|16:00|2|4|2|\n",
    "\n",
    "\n",
    "De esta forma, podemos usar los valores `lags` como input para predecir el valor en tiempo `t`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación cruzada para series temporales\n",
    "\n",
    "Sabemos que la apliación de algoritmos de ML implica encontrar el mejor balance entre error de bies y error de varianza. En un caso normal, esto se consigue mediante validación crruzada en la que ejemplos del dataset de entrenamiento son seleccionados aleatoriamente como subset de validación, sobre el que estimaremos el rendimiento de nuestro modelo.\n",
    "\n",
    "En series temporales, tenemos un caso distinto. El problema que queremos resolver es predecir un valor en el futuro, por lo que el subset de `validación` **siempre tendra que ocurrrir despues** del subset de entrenamiento. De forma intuitiva, piensa que no deberíamos predecir el tiempo que va a hacer mañana usando como variable el tiempo que va a hacer pasado mañana.\n",
    "\n",
    "En general:\n",
    "\n",
    "- Nuestro subset de testeo debe ocurrir despues de nuestro subset de entrenamiento.\n",
    "- No podemos coger datapoints de forma aleatoria ya que tendremos variables que son indicadores de lag que pueden filtrarnos informacion. Esto nos fuerza a trabajar con bloques de tiempo contiguos.\n",
    "\n",
    "La figura de abajo muestra patrones comunes de train - test:\n",
    "\n",
    "![ts cross-validation illustration](img/cv-ts.png)\n",
    "\n",
    "\n",
    "## Ventajas de usar ML para series temporales\n",
    "\n",
    "- Familiaridad de los algoritmos de regresion: regresion lineal, ensemble tree models, redes neuronales...\n",
    "- Optimizacion de hiperparapetros\n",
    "- Incluir features adicionales que nos aporten información contextual: temperatura, si es fin de semana, ...\n",
    "\n",
    "Nota final:\n",
    "\n",
    "Para las series temporales `facebook` publicó recientemente [prophet](https://facebook.github.io/prophet/docs/quick_start.html#python-api.). El way to go para hacer una prueba rapida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Carga las librerías as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as ##\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Cargamos los datos en un df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset representa el uso de bicicletas compartidas (`cnt`) en un día en función del día y de las variables ambientales de ese dia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Convierte el campo `dteday` tipo `datetime`.\n",
    "\n",
    "pandas tiene una utilidad para ello...`pd.to_datetime()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dteday'] = ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Vamos a empezar visualizando nuestra serie temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ##\n",
    "df.set_index('dteday')[column].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Vamos a crear nuevas variables que reflejen la dependencia temporal:\n",
    "\n",
    "* Los tres ultimos lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lags(df, field, n_lags):\n",
    "    for lag in range(1, n_lags+1):\n",
    "        df[field + f'_t-{str(lag)}'] = df[field].shift(##)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_lags(df, 'cnt', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La media móvil de los ultimos 7 días"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(df, field, n_lags):\n",
    "    df[f'mvng_avg_{field}_{n_lags}'] = df[field].rolling(window=##).mean()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = moving_average(df, 'cnt', 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('dteday')[['cnt', 'mvng_avg_cnt_7']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La media movil de los 7 días anteriores de hace un año de la fecha de hoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['last_year_date'] = df['dteday'] - pd.offsets.DateOffset(years=1)\n",
    "df = df.rename(columns={'last_year_date': 'to_cross'}).merge(\n",
    "    df[['dteday', 'mvng_avg_cnt_7']].rename(columns={'dteday': 'to_cross'}),\n",
    "    on='to_cross',\n",
    "    suffixes=['_cy', '_ly'],\n",
    "    how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check is well calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_cy = '2012-12-28'\n",
    "day_ly = '2011-12-28'\n",
    "\n",
    "display(df[df['dteday'] == day_cy][['dteday', 'mvng_avg_cnt_7_cy', 'mvng_avg_cnt_7_ly']])\n",
    "display((df[df['dteday'] == day_ly][['dteday', 'mvng_avg_cnt_7_cy', 'mvng_avg_cnt_7_ly']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('dteday')[['cnt', 'mvng_avg_cnt_7_cy', 'mvng_avg_cnt_7_ly']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The ratio between the moving average of last year wrt current year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['increase_wrt_ly'] = ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['increase_wrt_ly'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['increase_wrt_ly'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parece que la demanda ha crecido entre un ###**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_cv = TimeSeriesSplit(n_splits=5,\n",
    "                        gap=2, # leave 2 days out between train and test\n",
    "                        test_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TimeSeriesSplit nos devuelve un generador que pasamos a lista. Esta lista contiene los indices que se utilizarán para separar el df entre train y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_splits = list(ts_cv.split(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the initial splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, split in enumerate(all_splits):\n",
    "    train_indexes = split[0]\n",
    "    test_indexes = split[1]\n",
    "    df.iloc[##].set_index('dteday')['cnt'].plot()\n",
    "    df.iloc[##].set_index('dteday')['cnt'].plot()\n",
    "    plt.title(f'Split {ix}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos a entrenar un modelo para ver como se comportat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_columns = ['season', 'yr', 'mnth', 'holiday', 'weekday',\n",
    "             'workingday', 'weathersit', 'temp', 'atemp', 'hum',\n",
    "             'windspeed','cnt_t-1', 'cnt_t-2',\n",
    "             'cnt_t-3', 'mvng_avg_cnt_7_cy', 'increase_wrt_ly']\n",
    "y_col = ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[X_columns]\n",
    "y = df[y_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OJO: No incluimos la media movil del año pasado por que nos va a introducir muchos nulos y es dificil de imputar. Hemos visto que el crecimiento de este año ha sido del ~60%. Podemos hacer varias pruebas y ver que pasa si imputamos el campo `increase_wrt_ly` con ese 60% o asumimos que no hubo crecimiento con respecto al año pasado (imputar 1). Asumiremos este ultimo caso a falta de datos por ser más conservador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['increase_wrt_ly'] = X['increase_wrt_ly'].fillna(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La media movil no sé puede calcular para los primeros 6 lags. Vamos a imputar con el primer valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['mvng_avg_cnt_7_cy'] = X['mvng_avg_cnt_7_cy'].fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[['cnt_t-1', 'cnt_t-2', 'cnt_t-3']] = X[['cnt_t-1', 'cnt_t-2', 'cnt_t-3']].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for ix, (train_index, test_index) in enumerate(all_splits):\n",
    "\n",
    "    data_train   = X.iloc[##]\n",
    "    target_train = y.iloc[##]\n",
    "\n",
    "    data_test    = X.iloc[##]\n",
    "    target_test  = y.iloc[##]\n",
    "\n",
    "    reg = RandomForestRegressor()\n",
    "    reg.fit(data_train, target_train)\n",
    "\n",
    "    preds = reg.predict(data_test)\n",
    "\n",
    "    # rmse for the current fold only    \n",
    "    rmse = np.sqrt(mean_squared_error(##, ##))\n",
    "\n",
    "    scores.append(rmse)\n",
    "    plt.title(f'Set {ix} - RMSE {rmse}')\n",
    "    plt.plot(train_index, target_train, label='train')\n",
    "    plt.plot(test_index, target_test, label='test')\n",
    "    plt.plot(test_index, preds, label='preds')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# this is the average accuracy over all folds\n",
    "average_score = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X.columns\n",
    "importances = reg.##\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspeccionando el Random Forest vemos que la variable más importante es la media movil de la semana y entre las más importantes las features de `lag`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exit Points\n",
    "\n",
    "Crear variables de series temporales puede ser tedioso y complicado.\n",
    "\n",
    "Existen librerias que nos ayudan a trabajar con series temporales:\n",
    "\n",
    "* [sktime](https://github.com/alan-turing-institute/sktime): A sklearn type library for TS\n",
    "* [tsfresh](https://tsfresh.readthedocs.io/en/latest/): Automatically calculates a large number of time series characteristics, the so called features."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "uib",
   "language": "python",
   "name": "uib"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
