{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Caso de uso: Análisis exploratorio\n",
    "***\n",
    "\n",
    "##  DataLovers, S.A.\n",
    "\n",
    "Durante este fin de semana, una nueva consultoría ha aparecido en el panorama empresarial de la ciudad. Somos una empresa joven, de unas horas de antigüedad, pero con algunos clientes importantes que necesitan soluciones a sus problemas.\n",
    "***\n",
    "\n",
    "## Welcome aboard \\!\n",
    "\n",
    "Hoy es tú primer día de trabajo y, después de haberte tomado el café a coste de la empresa y comentar el apasionante Mali-Ghana del mundial SUB-17 del fin de semana, te han asignado tu primera tarea para un nuevo cliente: **LargeInternationalCorporation, INC.**\n",
    "\n",
    "El CEO de la empresa, un oligarca ruso sin escrupulos que hizo fortuna durante la caída del imperio sovietico con la ayuda de los amigos correctos, está preocupado por la alta tasa de abandono que tiene entre sus empleados. Parece ser que con los años Don Sergey Sokolov se ha dado cuenta de que entender los factores que se asocián con la tasa de abandono le permitirá mantener a los empleados contentos para evitar que se vayan y, quién sabe, incluso aumentar su productividad. Cómo las vacas: cuanto más felices, más leche.¹\n",
    "***\n",
    "\n",
    "## Tarea (para ayer)\n",
    "\n",
    "No te han dado más información que un set de datos y una guía descriptiva de los campos que contiene. Así que la tarea consiste en intentar extraer la mayor cantidad de información posible de los datos y sacar alguna conclusiones para poder ayudar a reducir el número de bajas de la empresa del Sr. Sokolov.\n",
    "***\n",
    "\n",
    "## El método\n",
    "Te han contratado como data scientist. Eso es lo que eres, un científico. Y la ciencia se basa en dos pilares fundamentales. La metodología y la reproducibilidad.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<div class=\"panel panel-success\">\n",
    "  <div class=\"panel-heading\">El método científico</div>\n",
    "  <div class=\"panel-body\">\n",
    "      <ol>\n",
    "        <li>Observación</li>\n",
    "        <li>Hipótesis</li>\n",
    "        <li>Experimentación</li>\n",
    "        <li>Teoría</li>\n",
    "        <li>Ley</li>\n",
    "      </ol>\n",
    "   </div>\n",
    "</div>\n",
    "\n",
    "Una versión adaptada a los datos del método científico podría consistir en²:\n",
    "\n",
    "1. Empezar con datos\n",
    "1. Desarrollar una intuición sobre los datos y las preguntas que puede responder\n",
    "1. Hacer la pregunta adecuada\n",
    "1. Intentar reponderla con los datos y, si no se puede, iterar sobre los puntos anteriores hasta que tengamos una hipótesis que queremos testear.\n",
    "1. Crear un entorno donde podamos probar nuestra hipótesis\n",
    "1. Analizar los resultados\n",
    "\n",
    "Otra forma de decirlo a la americana, es el proceso OSEMN,³ pronunciado awesome.\n",
    "\n",
    "1. **O**btain data: automatizar la obtención de datos! SQL en databases, web scraping y scripting usando Python y/o shell scripts.\n",
    "1. **S**crub data: los datos estan sucios. Limpialos.\n",
    "1. **E**xplore data: conoce tus datos antes de empezar a filosofar\n",
    "1. **M**odel data: Crea un modelo predictivo a partir de tus datos\n",
    "1. I**N**terpret results: Que nos dice el modelo con respecto a los datos? Tiene sentido? Se puede interpretar?\n",
    "\n",
    "\n",
    "Sencillo, verdad? Respuesta: No.\n",
    "\n",
    "\n",
    "<sub>1. http://www.nacion.com/vivir/ambiente/Vacas-felices-producen-leche_0_1645235488.html</sub>\n",
    "\n",
    "<sub> 2. [Data Driven, DJ Patil](http://www.oreilly.com/data/free/data-driven.csp). </sub>\n",
    "\n",
    "<sub> 3. https://machinelearningmastery.com/how-to-work-through-a-problem-like-a-data-scientist/ </sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparando el entorno\n",
    "***\n",
    "Antes de nada, debemos preparar el entorno para poder empezar a trabajar. Importa las librerías básicas para poder realizar análisis de datos en `python` y poder visualizar los plots en el notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El \"ipython magic\" que permite ver los plots en notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "# pandas bajo el alias pd\n",
    "import pandas as ##\n",
    "\n",
    "# numpy bajo el alias ##\n",
    "import numpy as ##\n",
    "\n",
    "# matplotlib.pyplot bajo el alias plt\n",
    "import matplotlib.pyplot as ##\n",
    "\n",
    "# seaborn bajo el alias sns\n",
    "import seaborn as ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Obtención de los datos\n",
    "***\n",
    "Tenemos suerte y nos han pasado los datos en un csv. Importa el fichero como DataFrame de pandas y guardalo en la variable `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa el archivo \"HR_data.csv\"\n",
    "df = ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un primer paso es ver como lucen nuestros datos. Echale un vistazo a las primeras lineas del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Chequeo y limpieza\n",
    "***\n",
    "Examinemos el set de datos para ver si todo parece correcto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Echale un vistazo a las columnas del set de datos\n",
    "# y el tipo de dato que \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que todos los tipos de datos corresponden o son acordes con el nombre de la columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Que tamaño tiene nuestro set de datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Echale un vistazo a las primeras filas del set de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vaya, parece que hay algún dato que falta. Aunque no lo parezca, hemos tenido suerte de que aparezca algún nulo en el head. Así no nos olvidamos de un paso clave: mirar de manera más exhaustiva si hay otras columnas que puedan contener valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Comprueba que columnas tienen valores nulos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utiliza el metodo any() al final de la sentencia anterior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprueba las filas que tienen valores nulos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tip: Podemos pasar los valores que nos devuelve el df.isnull()\n",
    "# para filtrar el df. Echale un vistazo a la documentación o busca\n",
    "# en stackoverflow cómo hacerlo\n",
    "\n",
    "mask = ## \n",
    "df[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que hacemos con los nulos? Depende. Se puede salvar alguno? Nos va a afectar al conjunto de los datos? Antes de responder, veamos un descriptivo básico del df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realiza un análisis descriptivo del df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sabemos de antes que el set de datos tiene 14999 entradas y que hay nulos en cuatro columnas. Solo en una de ellas parece que se podría salvar de forma segura ya que parece que ha habido un error en el parseo.\n",
    "\n",
    "Vamos a arreglar primero ese valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encuentra la fila con valores de salary nulos \n",
    "# y guarda el indice de la fila en una variable\n",
    "cols = ['sales', 'salary']\n",
    "print(df[df['salary'].isnull()][cols])\n",
    "\n",
    "idx_salary_nan = ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asigna los valores correctos\n",
    "\n",
    "df['sales'].loc[idx_salary_nan] = 'accounting'\n",
    "df['salary'].loc[idx_salary_nan] = 'low'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['sales', 'salary']\n",
    "print(df[cols].loc[idx_salary_nan])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vamos a imputar el valor nulo de satisfaction_level con la media de la columna.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula la media de la columna\n",
    "mean_satisfaction_level = ##\n",
    "\n",
    "# Usa el método fillna() para rellenar el nulo con el valor calculado\n",
    "\n",
    "df['satisfaction_level'] = ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['satisfaction_level'].isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que hacemos con el resto?\n",
    "Vemos que representan una fracción infima del set de datos total (2/14999 = 0.013%). Nos los cargamos sin piedad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por último, vamos a renombrar las columnas por nombres más explicativos y a poner la etiqueta de si ha dejado la empresa o no en primer lugar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'satisfaction_level': 'satisfaction', \n",
    "                        'last_evaluation': 'evaluation',\n",
    "                        'number_project': 'projectCount',\n",
    "                        'average_montly_hours': 'averageMonthlyHours',\n",
    "                        'time_spend_company': 'yearsAtCompany',\n",
    "                        'Work_accident': 'workAccident',\n",
    "                        'promotion_last_5years': 'promotion',\n",
    "                        'sales' : 'department',\n",
    "                        'left' : 'turnover'\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mueve la variable al frente de la lista de columnas\n",
    "\n",
    "# 1 - asigna la serie a una variable\n",
    "turnover_values = ##\n",
    "\n",
    "# 2 - Deja caer (drop()) la columna del df\n",
    "df = df.drop(##)\n",
    "\n",
    "# 3 - Inserta (df.insert()) la columna en primer lugar\n",
    "df.insert(loc=0, column='turnover', value=##)\n",
    "\n",
    "# 4 - Enseña las primeras filas\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que nuestro set de datos esta limpio y listo para ser explorado. Vamos a guardarlo de forma que se salven los cambios, por si acaso se nos cae el kernel o tengamos que entregar el set de datos limpio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a comprobar que el ficher se ha creado. Podemos ejecutar comandos bash desde una celda de iPython poniendo  `!` al principio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Explorar datos\n",
    "***\n",
    "\n",
    "Esta sección exploraremos los datos de forma más o menos exhaustiva. Nos basaremos en un análisis estadístico básico y crearemos unos gráficos que nos ayuden a comprender los parametros.\n",
    "\n",
    "Recuerda que estamos examinando los datos intentando responder a una pregunta. Por qué la gente se va da la empresa?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Exploración básica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Que porcentage de gente abandona la empresa?\n",
    "# El método value_counts() nos agrupa directamente por la columna seleccionada y nos cuenta cuantos valores\n",
    "# hay de cada elemento único\n",
    "\n",
    "numero_observaciones = ##\n",
    "\n",
    "tasa_bajas = ## / numero_observaciones\n",
    "print(tasa_bajas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como son los descriptivos estadisticos básico de todo el dataset?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y por gente que lo deja o no lo deja?\n",
    "# Haz un groupby por 'turnover' y utiliza otra vez la funcion describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qué primeras conclusiones sacas?\n",
    "\n",
    "A primera vista, hay alguna diferencia en algunos de las caracteristicas para cada uno de los grupos?\n",
    "\n",
    "Hay algo que te llame la atención?\n",
    "\n",
    "Utiliza la casilla Markdown de abajo para escribir tus conclusiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones 3.1 Exploración básica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Correlación entre variables\n",
    "***\n",
    "Normalmente, algunas variables presentaran correlaciones entre sí. De forma positiva, como la temperatura ambiente y el consumo de helado, o negativas, como la temperatura ambiente y el número de capas de ropa que llevo.\n",
    "\n",
    "En este apartado vamos a tratar de ver cómo se correlacionan las variables entre si, y ver si podemos extraer algún tipo de información de esta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcula la matriz de correlación usando df.corr()\n",
    "\n",
    "corr = ##\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque no imposible, es dificil ver las tendencias a partir de valores numéricos, y eso que solo tenemos 10 variables!\n",
    "Vamos a intentar plotear un mapa de calor que nos diga cómo se correlacionan. Usaremos **seaborn** y [éste](http://seaborn.pydata.org/examples/many_pairwise_correlations.html) snippet de codigo para generar un plot informativo y que nos entre por la vista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Crea una funcion llamada correlation_plot a partir del snippet mencionado arriba que nos cree un plot dado\n",
    "### un df de pandas y las columnas que queremos usar. Si no se especifican las columnas, usar todo el df\n",
    "\n",
    "def correlation_plot(df, cols=None):\n",
    "    \"\"\"\n",
    "    Dada una matriz de correlacion, genera un heatmap para visualizar\n",
    "    las correlaciones entre las variables.\n",
    "    \"\"\"\n",
    "    \n",
    "    if cols:\n",
    "        corr = ##\n",
    "    else:\n",
    "        corr = ##\n",
    "\n",
    "    # Generate a mask for the upper triangle\n",
    "    mask = np.zeros_like(corr, dtype=bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    # Set up the matplotlib figure\n",
    "    f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "    # Generate a custom diverging colormap\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    sns.heatmap(##, mask=mask, cmap=cmap, vmax=0.3, center=0,\n",
    "                square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_plot(df, cols=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Que correlaciones positivas y negativas hay entre el turnover y el resto de variables?**\n",
    "\n",
    "Correlaciones positivas:\n",
    "    * variables?\n",
    "    \n",
    "Correlaciones negativas:\n",
    "    * variables?\n",
    "\n",
    "** Qué variables presentan correlaciones fuertes entre sí? **\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### 3.3 Investigando las correlaciones\n",
    "***\n",
    "Hemos visto que el abandono de la empresa esta fuertemente correlacionado con la satisfacción en la empresa.\n",
    "\n",
    "Podemos determinar si existe una diferencia significativa entre la satisfacción de los empleados que continuan o que dimiten?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula la media y la desviación estandar de la satisfacción\n",
    "# de los empleados que abandonan o se quedan en la empresa\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcula la desviación estandar\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=##, x=##, y=##)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=##, x=##, hue=##)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realmente a partir de las medias y desviaciones obtenidas, así como por la dispersión de los datos en los plots, parece que tenemos una clara distinción en la satisfacción de la gente que abandona la empresa o se queda.\n",
    "\n",
    "Podríamos darle un poco más de solidez haciendo un test estadístico?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scipy es la libreria cientifica de python. Entre otras,\n",
    "# contiene una librería muy potente de estadística con la que\n",
    "# podremos hacer analísis de hipótesis.\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtra el df de forma que devuelva solo los valores de satisfaccino\n",
    "# que corresponden a gente que ha abandonado la empresa, i.e.: turnover == 1\n",
    "\n",
    "valores_satisfaccion_abandono = ##\n",
    "\n",
    "valores_satisfaccion_no_abandono = ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H_0: \\mu(satisfaction)_{aband} = \\mu(satisfaction)_{NoAband} $\n",
    "\n",
    "$H_1: \\mu(satisfaction)_{aband} \\not=  \\mu(satisfaction)_{NoAband} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Que test estadístico podríamos usar para evaluar la hipotesis nula?\n",
    "ks_statistic, ks_p = stats.ks_2samp(valores_satisfaccion_abandono,\n",
    "                                    valores_satisfaccion_no_abandono)\n",
    "print(ks_statistic, ks_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos rechazar $H_0$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parece ser que estamos llegando a una conclusión sólida de que los empleados menos satisfechos son los que tienen más riesgo de abandonar la empresa. Pero, que causa que los empleados estén insatisfechos?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecuta la celda para ver el resultado de plotear variable a variable los scatter plots.\n",
    "# En la diagonal apareceran los kde de los histogramas\n",
    "\n",
    "sns.pairplot(data=df.sample(frac=0.2),\n",
    "             hue='turnover',\n",
    "             diag_kind='kde',\n",
    "             palette=\"husl\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que conclusiones podemos sacar a partir de lo de arriba?\n",
    "\n",
    "Te llama la atención el plot de satisfacción vs. evaluación?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Enfasis en salario\n",
    "\n",
    "Por último, vamos a intentar ver una de las variables que hemos pasado por alto. El salario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# muestra los valores de salarios que hay en la tabla\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cómo se reparten los salarios entre los empleados\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investiguemos la repartición entre los que han abandonado la empresa y los que se han quedado\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hmmm, mejor veamoslo\n",
    "\n",
    "sns.countplot(data=df, x='salary', hue='turnover', palette='husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm, los que menos cobrán son los que tienen más tendencia a irse de la empresa.\n",
    "\n",
    "Podrías decir algo entre las horas trabajadas, el número de proyectos y el hecho de que los empleados se vayan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usa la opción de boxplot de seaborn.\n",
    "sns.boxplot(x=\"projectCount\", y=\"averageMonthlyHours\", hue=\"turnover\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A estas alturas ya tenemos una idea de que variables pueden influirnos más a la hora de elaborar un modelos predictivo. Cada vez que desarrollemos un proyecto de ML, seguiremos esta aproximación:\n",
    "\n",
    "1. EDA + Limpieza (lo que acabamos de hacer)\n",
    "1. Determinar que métrica utilizaremos para determinar como de bien se comporta nuestro modelo\n",
    "1. Separar en train y test nuestro data set de entrenamiento\n",
    "1. Crear un modelo \"dummy\" de forma que sea la linea de base que utilizaremos para comparar nuestros modelos:\n",
    "    * en el caso de una clasificacion, el modelo más sencillo es predecir el \"prior\", es decir, la probabilidad de que una persona abandone la empresa (vamos, la media del target)\n",
    "1. Crear un modelo sencillo (modelo lineal) para explorar \"que\" está aprendiendo el modelo:\n",
    "    * Una de las ventajas de los modelos lineales es que podremos explorar directamente que peso se le da a cada feature\n",
    "1. Entrenar varios modelos para seleccionar que modelo nos funciona mejor (90% de los casos será un ensemble de arboles)\n",
    "1. Utilizar validación cruzada y gridsearch para determinar cuales son los mejores parametros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Igualmente, aunque parezca un proceso lineal, los proyecto de machine learning se caracterizan por ser de naturaleza iterativa. Hay varias metodologías que resumen el ciclo de vida, uno de los más conocidos es el CRISP-DM\n",
    "\n",
    "**Cross-Industry Standard Process for the development of Machine Learning applications with Quality assurance methodology**\n",
    "\n",
    "![\"img/crisp-ml-process.jpeg\"](img/crisp-ml-process.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide en train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Queremos asegurarnos que la distribución de turnover es similar en train y test así que usaremos el stratify\n",
    "df_train, df_test = train_test_split(##,\n",
    "                                     test_size=##,\n",
    "                                     stratify=df['turnover'],\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprueba que las distribuciones son iguales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calcula la media del turnover en cada subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creamos X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ##\n",
    "y_train = ##\n",
    "\n",
    "X_test = ## \n",
    "y_test = ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy classifier de sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dummy = DummyClassifier(strategy='prior')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dummy.fit(##, ##)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_dummy = clf_dummy.predict_proba(##)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluamos usando la curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dummy = roc_auc_score(y_true=##,\n",
    "                            y_score=##\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('score_dummy:', score_dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creamos un modelo lineal para ver el caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr = ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preselección de columnas basado en el EDA\n",
    "cols = ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr.fit(X_train[cols], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_lr = clf_lr.predict_proba(X_test[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_lr = roc_auc_score(y_test, y_hat_lr[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('score_lr:', score_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos a revisar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, col in enumerate(cols):\n",
    "    print(col, clf_lr.coef_[0][ix])\n",
    "print('intercept', clf_lr.intercept_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tienen sentido con respecto al know-how que hemos obtenido con respecto al EDA?**\n",
    "\n",
    "**Tiene sentido comparar los parametros directamente ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenemos un random forest (no lineal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf.fit(X_train[cols], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_rf = clf_rf.predict_proba(X_test[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_rf = roc_auc_score(y_test, y_hat_rf[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Not bad!** pero... como podemos estar seguros de que no hay Overfit ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': ##,\n",
    "              'max_depth': ##\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_gs = GridSearchCV(estimator=clf_rf,\n",
    "                      param_grid=param_grid,\n",
    "                      scoring='roc_auc',\n",
    "                      cv=##,\n",
    "                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_gs.fit(X_train[cols], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(##)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_rf_gs = clf_gs.predict_proba(X_test[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_rf_gs = roc_auc_score(y_test, y_hat_rf_gs[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Score rf gs', score_rf_gs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uib",
   "language": "python",
   "name": "uib"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
